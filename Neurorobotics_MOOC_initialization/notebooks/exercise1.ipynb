{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Exercise 1</center>\n",
    "## <center>Make the robot explore its environment by following Braitenberg rules</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "\n",
    "-------------------------------------\n",
    "\n",
    "### Initialization.\n",
    "\n",
    "You need to install the [Virtual Coach](https://developer.humanbrainproject.eu/docs/projects/HBP%20Neurorobotics%20Platform/2.0/nrp/user_manual/virtual_coach/introduction.html) and the [HBP Service Client](https://collab.humanbrainproject.eu/#/collab/509/nav/24072).\n",
    "\n",
    "- **[Virtual Coach](https://developer.humanbrainproject.eu/docs/projects/HBP%20Neurorobotics%20Platform/2.0/nrp/user_manual/virtual_coach/introduction.html)** is a Python API that allows you to run and interact with the experiments of the [Neurorobotics platform](http://148.187.97.48/#/esv-private) by scripting them instead of having to use the Web Cockpit.\n",
    "- **[HBP Service Client](https://collab.humanbrainproject.eu/#/collab/509/nav/24072)** is a Python API that provides convenient access to Collaboratory's Storage service.\n",
    "\n",
    "<font color=red>__Important:__</font> Run the cell below everytime you open this Jupyter notebook to install requered utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "# Install NRP's VirtualCoach\n",
    "!pip install -i https://bbpteam.epfl.ch/repository/devpi/simple  hbp-nrp-virtual-coach==2.1.2 \n",
    "# Install HBP's ServiceClient\n",
    "!pip install --upgrade \"hbp-service-client==1.1.1\"\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "\n",
    "--------------------------------------------\n",
    "\n",
    "### Content:\n",
    "- <font size=\"4\">[A. Fill in the gaps of the Braitenberg controller [NRP platform]](#A)</font>\n",
    "- <font size=\"4\">[B. Launch the neurorobotics simulation of Exercise 1 ](#B)</font>\n",
    "- <font size=\"4\">[C. Record the robot positions](#C)</font>\n",
    "- <font size=\"4\">[D. Visualize the recorded robot positions](#D)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "\n",
    "--------------------------------------------\n",
    "\n",
    "## A. Fill in the gaps of the Braitenberg controller [NRP platform] <a id='A'></a>\n",
    "This part of the exercise shall be completed in the simulation environment of the [Neurorobotics Platform](http://148.187.97.48/#/esv-private).\n",
    "The [NRP User Manual]( https://developer.humanbrainproject.eu/docs/projects/HBP%20Neurorobotics%20Platform/2.0/nrp/user_manual/index.html) explains how to interact with the simulation and its embedded code editors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1. Copy Exercise 1's experiment template into your private storage\n",
    "\n",
    " You need first to take ownership of the template called *'Exercise 1: Make the robot explore ...'* by making a \n",
    " copy of it into your NRP private storage. This is a 3-step process: \n",
    "\n",
    " - (1) Join the [Neurorobotics Platform](http://148.187.96.224/#/esv-private?dev) and select the *Templates* tab.\n",
    " - (2) Select the experiment whose title starts with \"Exercise 1\" (you can use the filter at the top right-end corner).\n",
    " - (3) Press the *Clone* button; now you own a copy of the experiment which is visible in *My Experiments* tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2. Tune actuator and sensor parameters in order to achieve exploration and obstacle avoidance\n",
    "Open the *Running Simulations* tab of the [Neurorobotics Platform](http://148.187.97.48/#/esv-private) and join the simulation you have just launched. Open then the [*Transfer Function Editor*](https://developer.humanbrainproject.eu/docs/projects/HBP%20Neurorobotics%20Platform/2.0/nrp/user_manual/user_interface/edit/7-gz3d-tf-editor.html) and edit the files *velocity_commands.py* and *laser_sensors_transmit.py*. Tweak the values of the parameters `lin_max`, `lin_factor` and `ang_factor` in the first file, and the values of `idx_right`, `x_0` and `y_0` in the second file until the robot starts exploring its environment while avoiding obstacles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3. Move automatically the robot when it gets stuck\n",
    "Open the [SMACH Script Editor](https://developer.humanbrainproject.eu/docs/projects/HBP%20Neurorobotics%20Platform/2.0/nrp/user_manual/user_interface/edit/7-gz3d-edit-simulation.html) and edit the file *move_robot.exd* so that the robot is moved every time it gets stuck. You need to add a new state of type `SetRobotPose` to the state machine. The [SMACH StateMachines documentation](https://developer.humanbrainproject.eu/docs/projects/HBP%20Neurorobotics%20Platform/2.0/nrp/tutorials/experiment/state_machines.html?highlight=state%20machine) provides you with the API and few examples.\n",
    "\n",
    "<font color=red>__Important:__</font> Save your changes and stop the simulation from the graphical user interface before going to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "\n",
    "--------------------------------------------\n",
    "## B. Launch a neurorobotics simulation <a id='B'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B.1.__ Install NRP's VirtualCoach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -i https://bbpteam.epfl.ch/repository/devpi/simple  hbp-nrp-virtual-coach==2.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "__B.2.__ Initialize NRP's Virtual Coach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remark:__ fill in your password when prompted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hbp_nrp_virtual_coach.virtual_coach import VirtualCoach\n",
    "print(\"Retrieving your HBP OIDC token\")\n",
    "token = oauth.get_token()\n",
    "print(\"token retrieved!\")\n",
    "vc = VirtualCoach(environment='dev', oidc_token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "__B.3.__ The following command will display the list of experiments located in your storage. <font color=red>\n",
    "    \n",
    "__Important:__</font> check that __*'Exercise1_0'*__ (possibly __*'Exercise1_<font color=red>i</font>'*__ if you made *i+1* copies) is one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vc.print_cloned_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "__B.4.__ Launch <font color=black>__*Exercise 1_i*__</font> 's  experiment. \n",
    "\n",
    "__Remark:__ copy from the list above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiment = raw_input('Experiment name: ')\n",
    "sim = vc.launch_experiment(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "__B.5.__ Stop the simulation\n",
    "\n",
    "We are done with the simulation now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "\n",
    "--------------------------------------------\n",
    "## C. Record the robot positions <a id='C'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C.1.__ <font color=blue>From now on, we assume that you correctly implemented the Braitenberg exploration behaviour of the robot.</font>\n",
    "You will launch __*Exercise 1*__ 's experiment again [(explained in part B)](#B) and let the simulation record the robot positions for a sufficiently long time so as to collect robot positions.\n",
    "\n",
    "__Remarks:__ \n",
    "- Input the name of __*Exercise 1_i*__ according to list of experiments you will see. \n",
    "- Input __simulation time__ in seconds. Please, be aware that expected sufficient time __is about 900 seconds__.\n",
    "- Once you have run an experiment you can join the simulation via the [Neurorobotics Platform](http://148.187.96.224/#/esv-private?dev) and check if the robot does a proper job. In the mean time, a transfer function is recording the robot position every 20 ms into the file __*'robot_positions.csv'*__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the Virtual Coach:\n",
    "from hbp_nrp_virtual_coach.virtual_coach import VirtualCoach\n",
    "username = raw_input('Username: ')\n",
    "\n",
    "# Fill in your password when prompted\n",
    "vc = VirtualCoach(environment='dev', oidc_username=username)\n",
    "vc.print_cloned_experiments()\n",
    "\n",
    "# Launch Exercise 1's experiment for a sufficiently long time\n",
    "experiment = raw_input('Experiment name: ')\n",
    "sim_time = input('Simulation time (s): ')\n",
    "\n",
    "# Display the list of experiments located in your storage\n",
    "sim = vc.launch_experiment(experiment)\n",
    "\n",
    "# Run the experiment\n",
    "sim.start()\n",
    "\n",
    "# Wait for simulation end. Check out the simulation process via NRP platform.\n",
    "import time; time.sleep(sim_time); sim.pause()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C.2.__ Retrieve the latest recorded robot positions from the NRP storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrieve the latest recorded positions\n",
    "filename = 'robot_positions.csv'\n",
    "csv_content = vc.get_last_run_csv_file(experiment, filename)\n",
    "# Write robot positions into file \n",
    "wr = open(filename, 'w')\n",
    "wr.write(csv_content)\n",
    "\n",
    "# Get service client information\n",
    "clients = get_hbp_service_client()\n",
    "collab_path = get_collab_storage_path()\n",
    "\n",
    "# Remove the previous recorded positions, if needed\n",
    "from os import path\n",
    "filepath = path.join(collab_path, filename)\n",
    "if clients.storage.exists(filepath): \n",
    "    clients.storage.delete(filepath)\n",
    "    \n",
    "# Upload the latest recorded robot positions to your Collab storage\n",
    "data = clients.storage.upload_file(filename, filepath, 'text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C.3.__ Stop the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "\n",
    "--------------------------------------------\n",
    "## D. Visualize the recorded robot positions <a id='D'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.1.** Transform the latest recorded positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from StringIO import StringIO\n",
    "from os import path\n",
    "filename = 'robot_positions.csv'\n",
    "\n",
    "# Download the latest recorded positions from your Collab storage\n",
    "clients = get_hbp_service_client()\n",
    "collab_path = get_collab_storage_path()\n",
    "filepath = path.join(collab_path, filename)\n",
    "clients.storage.download_file(filepath, path.join('.', filename))\n",
    "\n",
    "# Process data for visualization\n",
    "data = pd.read_csv(filename, delimiter=',',header=0).values\n",
    "positions = np.array([pd.to_numeric(data[:,0], errors='coerce'), pd.to_numeric(data[:,1], errors='coerce')]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.2.** Visualization: recorded robot positions as exploration data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "\n",
    "# Figure\n",
    "fig = plt.figure(0,figsize=(8, 6))\n",
    "plt.title('Exploration data collected by the robot')\n",
    "\n",
    "# Obstacles\n",
    "ax = fig.add_subplot(111)\n",
    "rect1 = patches.Rectangle((-1.0,-3.0), 2., 1., color='black'); ax.add_patch(rect1)\n",
    "rect2 = patches.Rectangle(( 1.0,-3.0), 1., 3., color='black'); ax.add_patch(rect2)\n",
    "rect3 = patches.Rectangle((-2.0, 0.0), 1., 2., color='black'); ax.add_patch(rect3)\n",
    "rect4 = patches.Rectangle((-2.0, 2.0), 3., 1., color='black'); ax.add_patch(rect4)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(positions[:,1], positions[:,0], s=4e-3, color='r')\n",
    "plt.axis([-4.8, 4.8, -4.8, 4.8])\n",
    "plt.gca().invert_yaxis()\n",
    "ax.axes.get_xaxis().set_visible(False)\n",
    "ax.axes.get_yaxis().set_visible(False)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
